{
  "id": "826e9405-9dad-4e49-b759-fc578a197d64",
  "revision": 0,
  "last_node_id": 21,
  "last_link_id": 36,
  "nodes": [
    {
      "id": 14,
      "type": "ImageUpscaleWithModel",
      "pos": [
        1510,
        50
      ],
      "size": [
        221.98202514648438,
        46
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [
        {
          "name": "upscale_model",
          "type": "UPSCALE_MODEL",
          "link": 14
        },
        {
          "name": "image",
          "type": "IMAGE",
          "link": 15
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            16
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.43",
        "Node name for S&R": "ImageUpscaleWithModel",
        "widget_ue_connectable": {}
      },
      "widgets_values": []
    },
    {
      "id": 8,
      "type": "VAEDecode",
      "pos": [
        1180,
        50
      ],
      "size": [
        210,
        46
      ],
      "flags": {},
      "order": 9,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 7
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 19
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            15,
            20
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.43",
        "Node name for S&R": "VAEDecode",
        "widget_ue_connectable": {}
      },
      "widgets_values": []
    },
    {
      "id": 9,
      "type": "SaveImage",
      "pos": [
        1510,
        150
      ],
      "size": [
        455.989990234375,
        553.0900268554688
      ],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 16
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.43",
        "Node name for S&R": "SaveImage",
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        "ComfyUI"
      ]
    },
    {
      "id": 16,
      "type": "PreviewImage",
      "pos": [
        1180,
        150
      ],
      "size": [
        290,
        330
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 20
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.43",
        "Node name for S&R": "PreviewImage",
        "widget_ue_connectable": {}
      },
      "widgets_values": []
    },
    {
      "id": 5,
      "type": "EmptyLatentImage",
      "pos": [
        10,
        370
      ],
      "size": [
        310,
        110
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            2
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.43",
        "Node name for S&R": "EmptyLatentImage",
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        736,
        1128,
        1
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 13,
      "type": "UpscaleModelLoader",
      "pos": [
        10,
        60
      ],
      "size": [
        315,
        58
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "UPSCALE_MODEL",
          "type": "UPSCALE_MODEL",
          "slot_index": 0,
          "links": [
            14
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.43",
        "Node name for S&R": "UpscaleModelLoader",
        "models": [
          {
            "name": "RealESRGAN_x4plus.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Real-ESRGAN_repackaged/resolve/main/RealESRGAN_x4plus.safetensors",
            "directory": "upscale_models"
          }
        ],
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        "RealESRGAN_x4plus_anime_6B.pth"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 4,
      "type": "CheckpointLoaderSimple",
      "pos": [
        10,
        160
      ],
      "size": [
        315,
        98
      ],
      "flags": {},
      "order": 2,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "slot_index": 0,
          "links": [
            28
          ]
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "slot_index": 1,
          "links": [
            18,
            22
          ]
        },
        {
          "name": "VAE",
          "type": "VAE",
          "slot_index": 2,
          "links": [
            19
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.43",
        "Node name for S&R": "CheckpointLoaderSimple",
        "models": [
          {
            "name": "DreamShaper_8_pruned.safetensors",
            "url": "https://huggingface.co/Lykon/DreamShaper/resolve/main/DreamShaper_8_pruned.safetensors",
            "directory": "checkpoints"
          }
        ],
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        "animagine-xl-4.0-opt.safetensors"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 6,
      "type": "CLIPTextEncode",
      "pos": [
        370,
        50
      ],
      "size": [
        423.1099853515625,
        201.5616455078125
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 27
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            4
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.43",
        "Node name for S&R": "CLIPTextEncode",
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        "# 構図と品質\n1girl, solo, full body, centered composition, standing pose, masterpiece, best quality, anime style,\n\n# 髪型（シャープで内巻きしないストレートボブ、左目にかかる前髪）\ndark violet hair, sleek sharp straight bob cut, neat inward angle, clean ends, side bangs covering left eye, no hair curling at ends,\n\n# 顔立ち・表情（目を強化）\nslightly round youthful face, soft blush on cheeks,\nbig gentle amethyst eyes, highly detailed eyes, glossy eyes, sharp pupils, symmetrical eyes, clear highlights,\nconfident and secretive small smile, looking directly at camera, symmetrical face,\n\n# 衣装（黒＋紫基調のミステリアスで高級感あるアイドル衣装）\nwearing a high-end mysterious idol stage outfit:\nblack off-shoulder top with deep midnight purple accents and subtle glowing violet circuit thread pattern,\ndouble-layered skirt with outer layer in matte black and inner frill layer in soft metallic violet chiffon,\nholographic gradient sheen along skirt hem in violet to black tones,\ntight fitted techno-style waist belt with silver and purple buckle,\nthigh-high glossy black boots with faint violet neon glow and ribbon detail around ankles,\ngradient purple over-the-knee sheer socks blending into the boots,\nminimal black gloves with violet trims,\n\n# ポーズ\nstanding in secretive pose with one finger softly at lips,\nbody slightly angled, one leg relaxed, elegant and composed stance,\n\n# 背景\nwhite background, simple background, clean studio light,\n",
        [
          false,
          true
        ]
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 3,
      "type": "KSampler",
      "pos": [
        850,
        50
      ],
      "size": [
        310,
        480
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 32
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 4
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 6
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 2
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            7
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.43",
        "Node name for S&R": "KSampler",
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        23255246635345,
        "increment",
        28,
        5,
        "dpmpp_2m_sde",
        "karras",
        1
      ]
    },
    {
      "id": 17,
      "type": "LoraLoader",
      "pos": [
        347.9029235839844,
        629.0562133789062
      ],
      "size": [
        270,
        126
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 28
        },
        {
          "name": "clip",
          "type": "CLIP",
          "link": 23
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            35
          ]
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            36
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "LoraLoader",
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        "Niji_anime_illustrious.safetensors",
        1,
        1
      ]
    },
    {
      "id": 19,
      "type": "LoraLoader",
      "pos": [
        646.1637573242188,
        628.4393920898438
      ],
      "size": [
        270,
        126
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 35
        },
        {
          "name": "clip",
          "type": "CLIP",
          "link": 36
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            32
          ]
        },
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            27
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.48",
        "Node name for S&R": "LoraLoader",
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        "eyecolle_xl_code191.safetensors",
        1,
        1
      ]
    },
    {
      "id": 21,
      "type": "CLIPSetLastLayer",
      "pos": [
        13.548455238342285,
        578.1661376953125
      ],
      "size": [
        302.673828125,
        58
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 22
        }
      ],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            23
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.41",
        "Node name for S&R": "CLIPSetLastLayer",
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        -2
      ]
    },
    {
      "id": 7,
      "type": "CLIPTextEncode",
      "pos": [
        367.37799072265625,
        299.1773681640625
      ],
      "size": [
        423.1099853515625,
        180.61000061035156
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 18
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            6
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.43",
        "Node name for S&R": "CLIPTextEncode",
        "widget_ue_connectable": {}
      },
      "widgets_values": [
        "low quality, worst quality, bad anatomy, poorly drawn face,\ndeformed eyes, asymmetrical eyes, dull eyes, bad eyes, multiple pupils, creepy eyes,\nextra limbs, cropped, blurry, out of frame,\nwatermark, text, nsfw, loli, mature woman, heavy makeup,\ninconsistent outfit, duplicate costume, frilly white dress, fluffy skirt,\nlong hair, very long hair, waist-length hair, hip-length hair, floor-length hair\n",
        [
          false,
          true
        ]
      ],
      "color": "#223",
      "bgcolor": "#335"
    }
  ],
  "links": [
    [
      2,
      5,
      0,
      3,
      3,
      "LATENT"
    ],
    [
      4,
      6,
      0,
      3,
      1,
      "CONDITIONING"
    ],
    [
      6,
      7,
      0,
      3,
      2,
      "CONDITIONING"
    ],
    [
      7,
      3,
      0,
      8,
      0,
      "LATENT"
    ],
    [
      14,
      13,
      0,
      14,
      0,
      "UPSCALE_MODEL"
    ],
    [
      15,
      8,
      0,
      14,
      1,
      "IMAGE"
    ],
    [
      16,
      14,
      0,
      9,
      0,
      "IMAGE"
    ],
    [
      18,
      4,
      1,
      7,
      0,
      "CLIP"
    ],
    [
      19,
      4,
      2,
      8,
      1,
      "VAE"
    ],
    [
      20,
      8,
      0,
      16,
      0,
      "IMAGE"
    ],
    [
      22,
      4,
      1,
      21,
      0,
      "CLIP"
    ],
    [
      23,
      21,
      0,
      17,
      1,
      "CLIP"
    ],
    [
      27,
      19,
      1,
      6,
      0,
      "CLIP"
    ],
    [
      28,
      4,
      0,
      17,
      0,
      "MODEL"
    ],
    [
      32,
      19,
      0,
      3,
      0,
      "MODEL"
    ],
    [
      35,
      17,
      0,
      19,
      0,
      "MODEL"
    ],
    [
      36,
      17,
      1,
      19,
      1,
      "CLIP"
    ]
  ],
  "groups": [
    {
      "id": 1,
      "title": "Step 1- Load models",
      "bounding": [
        0,
        -20,
        330,
        300
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 2,
      "title": "Step2-Set image size",
      "bounding": [
        0,
        300,
        330,
        190
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Step3 - Prompt",
      "bounding": [
        350,
        -20,
        460,
        510
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 4,
      "title": "Second - Upscale image",
      "bounding": [
        1500,
        -20,
        475.989990234375,
        736.6900024414062
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 5,
      "title": "First - Image generation",
      "bounding": [
        830,
        -20,
        650,
        560
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.6303940863128614,
      "offset": [
        208.6920831367977,
        186.2854541798087
      ]
    },
    "frontendVersion": "1.25.11",
    "ue_links": [],
    "links_added_by_ue": [],
    "VHS_latentpreview": false,
    "VHS_latentpreviewrate": 0,
    "VHS_MetadataImage": true,
    "VHS_KeepIntermediate": true
  },
  "version": 0.4
}